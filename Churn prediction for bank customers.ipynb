{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4ad446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e72c1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the csv file\n",
    "# https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling\n",
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "#check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01d9d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the rows that are not needed\n",
    "df.drop(['RowNumber','CustomerId','Surname'],axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57932ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c696765220>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets plot a histogram to see which customers have or have not churned/exited according to tenure\n",
    "#According to the dataset. if Exited == 1 that means customer has churned and vice versa\n",
    "tenure_churned_no = df[df.Exited==0].Tenure\n",
    "tenure_churned_yes = df[df.Exited==1].Tenure\n",
    "plt.hist([tenure_churned_yes, tenure_churned_no], color = ['green','red'], label = ['Customer Retained', ' Customer Churned'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db64767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d62faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n",
      "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "#shows the unique values of every column, from this we can see what needs to be adjusted and scaled\n",
    "for column in df:\n",
    "    print(f'{column} : {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78abffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5de984e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France       0   42       2       0.00              1   \n",
       "1             608     Spain       0   41       1   83807.86              1   \n",
       "2             502    France       0   42       8  159660.80              3   \n",
       "3             699    France       0   39       1       0.00              2   \n",
       "4             850     Spain       0   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France       1   39       5       0.00              2   \n",
       "9996          516    France       1   35      10   57369.61              1   \n",
       "9997          709    France       0   36       7       0.00              1   \n",
       "9998          772   Germany       1   42       3   75075.31              2   \n",
       "9999          792    France       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change all values with 2 options to 0 and 1\n",
    "df['Gender'].replace({'Female':0,'Male':1},inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48067a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode remaining string values, in this case the Geography and NumOfProducts columns\n",
    "df = pd.get_dummies(data=df,columns=['Geography','NumOfProducts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7470328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
      " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
      " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
      " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
      " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
      " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
      " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
      " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
      " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
      " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
      " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
      " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
      " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
      " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
      " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
      " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
      " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
      " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
      " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
      " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
      " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
      " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
      " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
      " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
      " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
      " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
      " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
      " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
      " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
      " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
      " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
      " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
      " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
      " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
      " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
      " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
      " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
      " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
      " 0.124 0.064 0.046 0.138]\n",
      "Gender : [0 1]\n",
      "Age : [0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
      " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
      " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
      " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
      " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
      " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
      " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
      " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
      " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
      " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
      " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
      " 0.81081081 0.85135135 1.         0.87837838]\n",
      "Tenure : [0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
      "Balance : [0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
      "Exited : [1 0]\n",
      "Geography_France : [1 0]\n",
      "Geography_Germany : [0 1]\n",
      "Geography_Spain : [0 1]\n",
      "NumOfProducts_1 : [1 0]\n",
      "NumOfProducts_2 : [0 1]\n",
      "NumOfProducts_3 : [0 1]\n",
      "NumOfProducts_4 : [0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>NumOfProducts_1</th>\n",
       "      <th>NumOfProducts_2</th>\n",
       "      <th>NumOfProducts_3</th>\n",
       "      <th>NumOfProducts_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  HasCrCard  \\\n",
       "0           0.538       0  0.324324     0.2  0.000000          1   \n",
       "1           0.516       0  0.310811     0.1  0.334031          0   \n",
       "2           0.304       0  0.324324     0.8  0.636357          1   \n",
       "3           0.698       0  0.283784     0.1  0.000000          0   \n",
       "4           1.000       0  0.337838     0.2  0.500246          1   \n",
       "...           ...     ...       ...     ...       ...        ...   \n",
       "9995        0.842       1  0.283784     0.5  0.000000          1   \n",
       "9996        0.332       1  0.229730     1.0  0.228657          1   \n",
       "9997        0.718       0  0.243243     0.7  0.000000          0   \n",
       "9998        0.844       1  0.324324     0.3  0.299226          1   \n",
       "9999        0.884       0  0.135135     0.4  0.518708          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1         0.506735       1                 1   \n",
       "1                  1         0.562709       0                 0   \n",
       "2                  0         0.569654       1                 1   \n",
       "3                  0         0.469120       0                 1   \n",
       "4                  1         0.395400       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         0.481341       0                 1   \n",
       "9996               1         0.508490       0                 1   \n",
       "9997               1         0.210390       1                 1   \n",
       "9998               0         0.464429       1                 0   \n",
       "9999               0         0.190914       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  NumOfProducts_1  NumOfProducts_2  \\\n",
       "0                     0                0                1                0   \n",
       "1                     0                1                1                0   \n",
       "2                     0                0                0                0   \n",
       "3                     0                0                0                1   \n",
       "4                     0                1                1                0   \n",
       "...                 ...              ...              ...              ...   \n",
       "9995                  0                0                0                1   \n",
       "9996                  0                0                1                0   \n",
       "9997                  0                0                1                0   \n",
       "9998                  1                0                0                1   \n",
       "9999                  0                0                1                0   \n",
       "\n",
       "      NumOfProducts_3  NumOfProducts_4  \n",
       "0                   0                0  \n",
       "1                   0                0  \n",
       "2                   1                0  \n",
       "3                   0                0  \n",
       "4                   0                0  \n",
       "...               ...              ...  \n",
       "9995                0                0  \n",
       "9996                0                0  \n",
       "9997                0                0  \n",
       "9998                0                0  \n",
       "9999                0                0  \n",
       "\n",
       "[10000 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we need to scale the rest of the numbers to between 0 and 1 for the machine learning algorithm\n",
    "colsToScale = ['CreditScore','Age','Tenure','Balance','EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[colsToScale]=scaler.fit_transform(df[colsToScale])\n",
    "for column in df:\n",
    "    print(f'{column} : {df[column].unique()}')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2028b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>NumOfProducts_1</th>\n",
       "      <th>NumOfProducts_2</th>\n",
       "      <th>NumOfProducts_3</th>\n",
       "      <th>NumOfProducts_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  HasCrCard  \\\n",
       "0           0.538       0  0.324324     0.2  0.000000          1   \n",
       "1           0.516       0  0.310811     0.1  0.334031          0   \n",
       "2           0.304       0  0.324324     0.8  0.636357          1   \n",
       "3           0.698       0  0.283784     0.1  0.000000          0   \n",
       "4           1.000       0  0.337838     0.2  0.500246          1   \n",
       "...           ...     ...       ...     ...       ...        ...   \n",
       "9995        0.842       1  0.283784     0.5  0.000000          1   \n",
       "9996        0.332       1  0.229730     1.0  0.228657          1   \n",
       "9997        0.718       0  0.243243     0.7  0.000000          0   \n",
       "9998        0.844       1  0.324324     0.3  0.299226          1   \n",
       "9999        0.884       0  0.135135     0.4  0.518708          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "0                  1         0.506735                 1                  0   \n",
       "1                  1         0.562709                 0                  0   \n",
       "2                  0         0.569654                 1                  0   \n",
       "3                  0         0.469120                 1                  0   \n",
       "4                  1         0.395400                 0                  0   \n",
       "...              ...              ...               ...                ...   \n",
       "9995               0         0.481341                 1                  0   \n",
       "9996               1         0.508490                 1                  0   \n",
       "9997               1         0.210390                 1                  0   \n",
       "9998               0         0.464429                 0                  1   \n",
       "9999               0         0.190914                 1                  0   \n",
       "\n",
       "      Geography_Spain  NumOfProducts_1  NumOfProducts_2  NumOfProducts_3  \\\n",
       "0                   0                1                0                0   \n",
       "1                   1                1                0                0   \n",
       "2                   0                0                0                1   \n",
       "3                   0                0                1                0   \n",
       "4                   1                1                0                0   \n",
       "...               ...              ...              ...              ...   \n",
       "9995                0                0                1                0   \n",
       "9996                0                1                0                0   \n",
       "9997                0                1                0                0   \n",
       "9998                0                0                1                0   \n",
       "9999                0                1                0                0   \n",
       "\n",
       "      NumOfProducts_4  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "9995                0  \n",
       "9996                0  \n",
       "9997                0  \n",
       "9998                0  \n",
       "9999                0  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the values are all between 1 and 0 so we can now start the machine learning\n",
    "#lets split up the dataset into a training and testing dataset\n",
    "X = df.drop('Exited',axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3876021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= df['Exited']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4010cc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4369c51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3193de09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f6a3c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd20e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.10.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.50.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jerem\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d93f08fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 32, 15) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 32, 15), dtype=tf.float32, name='dense_19_input'), name='dense_19_input', description=\"created by layer 'dense_19_input'\"), but it was called on an input with incompatible shape (32, 15).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 32, 15) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 32, 15), dtype=tf.float32, name='dense_19_input'), name='dense_19_input', description=\"created by layer 'dense_19_input'\"), but it was called on an input with incompatible shape (32, 15).\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.5003 - accuracy: 0.7759\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8124\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3997 - accuracy: 0.8280\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8371\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8396\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8440\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8457\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8461\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8506\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8482\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8470\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8519\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8503\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8505\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8530\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8518\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8508\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8524\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8525\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8528\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8515\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8534\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8531\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8540\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8516\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8530\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8539\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8559\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8543\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8551\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8556\n",
      "Epoch 32/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8575\n",
      "Epoch 33/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8569\n",
      "Epoch 34/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8559\n",
      "Epoch 35/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8536\n",
      "Epoch 36/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8564\n",
      "Epoch 37/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8556\n",
      "Epoch 38/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8569\n",
      "Epoch 39/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8566\n",
      "Epoch 40/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8564\n",
      "Epoch 41/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8576\n",
      "Epoch 42/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8570\n",
      "Epoch 43/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8586\n",
      "Epoch 44/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8565\n",
      "Epoch 45/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8574\n",
      "Epoch 46/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8572\n",
      "Epoch 47/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8590\n",
      "Epoch 48/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8575\n",
      "Epoch 49/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8580\n",
      "Epoch 50/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8575\n",
      "Epoch 51/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8590\n",
      "Epoch 52/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8576\n",
      "Epoch 53/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8605\n",
      "Epoch 54/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8565\n",
      "Epoch 55/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8583\n",
      "Epoch 56/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8602\n",
      "Epoch 57/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3390 - accuracy: 0.8601\n",
      "Epoch 58/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3383 - accuracy: 0.8597\n",
      "Epoch 59/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3372 - accuracy: 0.8596\n",
      "Epoch 60/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8585\n",
      "Epoch 61/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3375 - accuracy: 0.8587\n",
      "Epoch 62/1000\n",
      "250/250 [==============================] - 0s 961us/step - loss: 0.3369 - accuracy: 0.8602\n",
      "Epoch 63/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8593\n",
      "Epoch 64/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3362 - accuracy: 0.8609\n",
      "Epoch 65/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3366 - accuracy: 0.8594\n",
      "Epoch 66/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8612\n",
      "Epoch 67/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8605\n",
      "Epoch 68/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8604\n",
      "Epoch 69/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8622\n",
      "Epoch 70/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8612\n",
      "Epoch 71/1000\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.3353 - accuracy: 0.8608\n",
      "Epoch 72/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8625\n",
      "Epoch 73/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8608\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8610\n",
      "Epoch 75/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8620\n",
      "Epoch 76/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8604\n",
      "Epoch 77/1000\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.3345 - accuracy: 0.8618\n",
      "Epoch 78/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3334 - accuracy: 0.8600\n",
      "Epoch 79/1000\n",
      "250/250 [==============================] - 0s 967us/step - loss: 0.3345 - accuracy: 0.8612\n",
      "Epoch 80/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8618\n",
      "Epoch 81/1000\n",
      "250/250 [==============================] - 0s 958us/step - loss: 0.3334 - accuracy: 0.8616\n",
      "Epoch 82/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3326 - accuracy: 0.8622\n",
      "Epoch 83/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8595\n",
      "Epoch 84/1000\n",
      "250/250 [==============================] - 0s 975us/step - loss: 0.3319 - accuracy: 0.8616\n",
      "Epoch 85/1000\n",
      "250/250 [==============================] - 0s 993us/step - loss: 0.3321 - accuracy: 0.8612\n",
      "Epoch 86/1000\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.3323 - accuracy: 0.8595\n",
      "Epoch 87/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8649\n",
      "Epoch 88/1000\n",
      "250/250 [==============================] - 0s 963us/step - loss: 0.3313 - accuracy: 0.8624\n",
      "Epoch 89/1000\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.3326 - accuracy: 0.8605\n",
      "Epoch 90/1000\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.3315 - accuracy: 0.8633\n",
      "Epoch 91/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8630\n",
      "Epoch 92/1000\n",
      "250/250 [==============================] - 0s 990us/step - loss: 0.3311 - accuracy: 0.8624\n",
      "Epoch 93/1000\n",
      "250/250 [==============================] - 0s 978us/step - loss: 0.3308 - accuracy: 0.8619\n",
      "Epoch 94/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3313 - accuracy: 0.8626\n",
      "Epoch 95/1000\n",
      "250/250 [==============================] - 0s 978us/step - loss: 0.3309 - accuracy: 0.8631\n",
      "Epoch 96/1000\n",
      "250/250 [==============================] - 0s 986us/step - loss: 0.3318 - accuracy: 0.8630\n",
      "Epoch 97/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3314 - accuracy: 0.8620\n",
      "Epoch 98/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3311 - accuracy: 0.8631\n",
      "Epoch 99/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8656\n",
      "Epoch 100/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3310 - accuracy: 0.8639\n",
      "Epoch 101/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3296 - accuracy: 0.8639\n",
      "Epoch 102/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3303 - accuracy: 0.8637\n",
      "Epoch 103/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3310 - accuracy: 0.8629\n",
      "Epoch 104/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3294 - accuracy: 0.8644\n",
      "Epoch 105/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3298 - accuracy: 0.8622\n",
      "Epoch 106/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3289 - accuracy: 0.8644\n",
      "Epoch 107/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8643\n",
      "Epoch 108/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3295 - accuracy: 0.8611\n",
      "Epoch 109/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3289 - accuracy: 0.8651\n",
      "Epoch 110/1000\n",
      "250/250 [==============================] - 0s 990us/step - loss: 0.3294 - accuracy: 0.8626\n",
      "Epoch 111/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
      "Epoch 112/1000\n",
      "250/250 [==============================] - 0s 965us/step - loss: 0.3291 - accuracy: 0.8655\n",
      "Epoch 113/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3288 - accuracy: 0.8634\n",
      "Epoch 114/1000\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.3285 - accuracy: 0.8654\n",
      "Epoch 115/1000\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.3286 - accuracy: 0.8654\n",
      "Epoch 116/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3282 - accuracy: 0.8629\n",
      "Epoch 117/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8641\n",
      "Epoch 118/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3277 - accuracy: 0.8640\n",
      "Epoch 119/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3265 - accuracy: 0.8649\n",
      "Epoch 120/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3278 - accuracy: 0.8646\n",
      "Epoch 121/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3270 - accuracy: 0.8640\n",
      "Epoch 122/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3270 - accuracy: 0.8655\n",
      "Epoch 123/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3273 - accuracy: 0.8633\n",
      "Epoch 124/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3273 - accuracy: 0.8634\n",
      "Epoch 125/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8652\n",
      "Epoch 126/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8635\n",
      "Epoch 127/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8654\n",
      "Epoch 128/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3273 - accuracy: 0.8654\n",
      "Epoch 129/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3260 - accuracy: 0.8633\n",
      "Epoch 130/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3259 - accuracy: 0.8641\n",
      "Epoch 131/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8641\n",
      "Epoch 132/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3264 - accuracy: 0.8659\n",
      "Epoch 133/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3260 - accuracy: 0.8643\n",
      "Epoch 134/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3283 - accuracy: 0.8615\n",
      "Epoch 135/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8666\n",
      "Epoch 136/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3248 - accuracy: 0.8659\n",
      "Epoch 137/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3252 - accuracy: 0.8645\n",
      "Epoch 138/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8659\n",
      "Epoch 139/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3252 - accuracy: 0.8661\n",
      "Epoch 140/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3253 - accuracy: 0.8641\n",
      "Epoch 141/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3248 - accuracy: 0.8655\n",
      "Epoch 142/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3248 - accuracy: 0.8658\n",
      "Epoch 143/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3246 - accuracy: 0.8644\n",
      "Epoch 144/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3241 - accuracy: 0.8655\n",
      "Epoch 145/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3248 - accuracy: 0.8664\n",
      "Epoch 146/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3261 - accuracy: 0.8648\n",
      "Epoch 147/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3243 - accuracy: 0.8662\n",
      "Epoch 148/1000\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.3247 - accuracy: 0.8669\n",
      "Epoch 149/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8676\n",
      "Epoch 150/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8660\n",
      "Epoch 151/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8658\n",
      "Epoch 152/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8656\n",
      "Epoch 153/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8662\n",
      "Epoch 154/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8645\n",
      "Epoch 155/1000\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8670\n",
      "Epoch 156/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8661\n",
      "Epoch 157/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8660\n",
      "Epoch 158/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8686\n",
      "Epoch 159/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8654\n",
      "Epoch 160/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8655\n",
      "Epoch 161/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8660\n",
      "Epoch 162/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8665\n",
      "Epoch 163/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8649\n",
      "Epoch 164/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8673\n",
      "Epoch 165/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8664\n",
      "Epoch 166/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8651\n",
      "Epoch 167/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8648\n",
      "Epoch 168/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8656\n",
      "Epoch 169/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8670\n",
      "Epoch 170/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8658\n",
      "Epoch 171/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8651\n",
      "Epoch 172/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8649\n",
      "Epoch 173/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8668\n",
      "Epoch 174/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8661\n",
      "Epoch 175/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8646\n",
      "Epoch 176/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8684\n",
      "Epoch 177/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8668\n",
      "Epoch 178/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8661\n",
      "Epoch 179/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8668\n",
      "Epoch 180/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8661\n",
      "Epoch 181/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8673\n",
      "Epoch 182/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8646\n",
      "Epoch 183/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8675\n",
      "Epoch 184/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8661\n",
      "Epoch 185/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8655\n",
      "Epoch 186/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.8659\n",
      "Epoch 187/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8664\n",
      "Epoch 188/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8679\n",
      "Epoch 189/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8680\n",
      "Epoch 190/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8659\n",
      "Epoch 191/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8683\n",
      "Epoch 192/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8649\n",
      "Epoch 193/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8674\n",
      "Epoch 194/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8670\n",
      "Epoch 195/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8683\n",
      "Epoch 196/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8662\n",
      "Epoch 197/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8683\n",
      "Epoch 198/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8680\n",
      "Epoch 199/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8665\n",
      "Epoch 200/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8692\n",
      "Epoch 201/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8671\n",
      "Epoch 202/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8679\n",
      "Epoch 203/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8690\n",
      "Epoch 204/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8662\n",
      "Epoch 205/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.8676\n",
      "Epoch 206/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8676\n",
      "Epoch 207/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8665\n",
      "Epoch 208/1000\n",
      "250/250 [==============================] - 0s 997us/step - loss: 0.3186 - accuracy: 0.8686\n",
      "Epoch 209/1000\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.3211 - accuracy: 0.8681\n",
      "Epoch 210/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8671\n",
      "Epoch 211/1000\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.3184 - accuracy: 0.8683\n",
      "Epoch 212/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8699\n",
      "Epoch 213/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8677\n",
      "Epoch 214/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8683\n",
      "Epoch 215/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8690\n",
      "Epoch 216/1000\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.3192 - accuracy: 0.8674\n",
      "Epoch 217/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8648\n",
      "Epoch 218/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8696\n",
      "Epoch 219/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8665\n",
      "Epoch 220/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8659\n",
      "Epoch 221/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8677\n",
      "Epoch 222/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8684\n",
      "Epoch 223/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8696\n",
      "Epoch 224/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8685\n",
      "Epoch 225/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8666\n",
      "Epoch 226/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8689\n",
      "Epoch 227/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8694\n",
      "Epoch 228/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8675\n",
      "Epoch 229/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8684\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8670\n",
      "Epoch 231/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8683\n",
      "Epoch 232/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.8668\n",
      "Epoch 233/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8680\n",
      "Epoch 234/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8673\n",
      "Epoch 235/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3176 - accuracy: 0.8668\n",
      "Epoch 236/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8685\n",
      "Epoch 237/1000\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8684\n",
      "Epoch 238/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8683\n",
      "Epoch 239/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8675\n",
      "Epoch 240/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8701\n",
      "Epoch 241/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8675\n",
      "Epoch 242/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8692\n",
      "Epoch 243/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8704\n",
      "Epoch 244/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8701\n",
      "Epoch 245/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8694\n",
      "Epoch 246/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8692\n",
      "Epoch 247/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8680\n",
      "Epoch 248/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8680\n",
      "Epoch 249/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8699\n",
      "Epoch 250/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3174 - accuracy: 0.8680\n",
      "Epoch 251/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3166 - accuracy: 0.8709\n",
      "Epoch 252/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.8677\n",
      "Epoch 253/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3168 - accuracy: 0.8699\n",
      "Epoch 254/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8669\n",
      "Epoch 255/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.8687\n",
      "Epoch 256/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8677\n",
      "Epoch 257/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8652\n",
      "Epoch 258/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8673\n",
      "Epoch 259/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8700\n",
      "Epoch 260/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8675\n",
      "Epoch 261/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8690\n",
      "Epoch 262/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8684\n",
      "Epoch 263/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8700\n",
      "Epoch 264/1000\n",
      "250/250 [==============================] - 0s 999us/step - loss: 0.3171 - accuracy: 0.8668\n",
      "Epoch 265/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8676\n",
      "Epoch 266/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8698\n",
      "Epoch 267/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8654\n",
      "Epoch 268/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8676\n",
      "Epoch 269/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8681\n",
      "Epoch 270/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8689\n",
      "Epoch 271/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8691\n",
      "Epoch 272/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8691\n",
      "Epoch 273/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8675\n",
      "Epoch 274/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8679\n",
      "Epoch 275/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8662\n",
      "Epoch 276/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8690\n",
      "Epoch 277/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8679\n",
      "Epoch 278/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8679\n",
      "Epoch 279/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8695\n",
      "Epoch 280/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8680\n",
      "Epoch 281/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8694\n",
      "Epoch 282/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8701\n",
      "Epoch 283/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8714\n",
      "Epoch 284/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.8679\n",
      "Epoch 285/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8686\n",
      "Epoch 286/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8690\n",
      "Epoch 287/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8677\n",
      "Epoch 288/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8706\n",
      "Epoch 289/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8676\n",
      "Epoch 290/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8689\n",
      "Epoch 291/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3146 - accuracy: 0.8702\n",
      "Epoch 292/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3154 - accuracy: 0.8687\n",
      "Epoch 293/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8687\n",
      "Epoch 294/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8680\n",
      "Epoch 295/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8696\n",
      "Epoch 296/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8687\n",
      "Epoch 297/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8700\n",
      "Epoch 298/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3153 - accuracy: 0.8698\n",
      "Epoch 299/1000\n",
      "250/250 [==============================] - 0s 994us/step - loss: 0.3154 - accuracy: 0.8696\n",
      "Epoch 300/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3153 - accuracy: 0.8690\n",
      "Epoch 301/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8683\n",
      "Epoch 302/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3147 - accuracy: 0.8709\n",
      "Epoch 303/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8691\n",
      "Epoch 304/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8704\n",
      "Epoch 305/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8702\n",
      "Epoch 306/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.8681\n",
      "Epoch 307/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8717\n",
      "Epoch 308/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 987us/step - loss: 0.3157 - accuracy: 0.8698\n",
      "Epoch 309/1000\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.3138 - accuracy: 0.8685\n",
      "Epoch 310/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3150 - accuracy: 0.8701\n",
      "Epoch 311/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8695\n",
      "Epoch 312/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.8701\n",
      "Epoch 313/1000\n",
      "250/250 [==============================] - 0s 978us/step - loss: 0.3147 - accuracy: 0.8684\n",
      "Epoch 314/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3143 - accuracy: 0.8690\n",
      "Epoch 315/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8702\n",
      "Epoch 316/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8676\n",
      "Epoch 317/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8696\n",
      "Epoch 318/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8701\n",
      "Epoch 319/1000\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.3143 - accuracy: 0.8692\n",
      "Epoch 320/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.8670\n",
      "Epoch 321/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3144 - accuracy: 0.8715\n",
      "Epoch 322/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8681\n",
      "Epoch 323/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3145 - accuracy: 0.8687\n",
      "Epoch 324/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8710\n",
      "Epoch 325/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.8699\n",
      "Epoch 326/1000\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.3143 - accuracy: 0.8700\n",
      "Epoch 327/1000\n",
      "250/250 [==============================] - 0s 997us/step - loss: 0.3145 - accuracy: 0.8705\n",
      "Epoch 328/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8695\n",
      "Epoch 329/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3140 - accuracy: 0.8700\n",
      "Epoch 330/1000\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.3139 - accuracy: 0.8692\n",
      "Epoch 331/1000\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.3137 - accuracy: 0.8694\n",
      "Epoch 332/1000\n",
      "250/250 [==============================] - 0s 998us/step - loss: 0.3137 - accuracy: 0.8715\n",
      "Epoch 333/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3144 - accuracy: 0.8677\n",
      "Epoch 334/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3144 - accuracy: 0.8677\n",
      "Epoch 335/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3140 - accuracy: 0.8694\n",
      "Epoch 336/1000\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.3140 - accuracy: 0.8698\n",
      "Epoch 337/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3142 - accuracy: 0.8690\n",
      "Epoch 338/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3134 - accuracy: 0.8700\n",
      "Epoch 339/1000\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.3149 - accuracy: 0.8681\n",
      "Epoch 340/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8681\n",
      "Epoch 341/1000\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.3132 - accuracy: 0.8710\n",
      "Epoch 342/1000\n",
      "250/250 [==============================] - 0s 966us/step - loss: 0.3132 - accuracy: 0.8717\n",
      "Epoch 343/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3142 - accuracy: 0.8695\n",
      "Epoch 344/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3137 - accuracy: 0.8712\n",
      "Epoch 345/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8692\n",
      "Epoch 346/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3142 - accuracy: 0.8687\n",
      "Epoch 347/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8702\n",
      "Epoch 348/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.8691\n",
      "Epoch 349/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8701\n",
      "Epoch 350/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8708\n",
      "Epoch 351/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.8695\n",
      "Epoch 352/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3133 - accuracy: 0.8720\n",
      "Epoch 353/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3131 - accuracy: 0.8717\n",
      "Epoch 354/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3138 - accuracy: 0.8711\n",
      "Epoch 355/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3126 - accuracy: 0.8702\n",
      "Epoch 356/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8696\n",
      "Epoch 357/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3141 - accuracy: 0.8716\n",
      "Epoch 358/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3128 - accuracy: 0.8692\n",
      "Epoch 359/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.8709\n",
      "Epoch 360/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3126 - accuracy: 0.8690\n",
      "Epoch 361/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3126 - accuracy: 0.8690\n",
      "Epoch 362/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8717\n",
      "Epoch 363/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.8712\n",
      "Epoch 364/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3122 - accuracy: 0.8705\n",
      "Epoch 365/1000\n",
      "250/250 [==============================] - 0s 975us/step - loss: 0.3127 - accuracy: 0.8704\n",
      "Epoch 366/1000\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.3122 - accuracy: 0.8709\n",
      "Epoch 367/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3114 - accuracy: 0.8721\n",
      "Epoch 368/1000\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.3124 - accuracy: 0.8710\n",
      "Epoch 369/1000\n",
      "250/250 [==============================] - 0s 993us/step - loss: 0.3121 - accuracy: 0.8709\n",
      "Epoch 370/1000\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.3117 - accuracy: 0.8714\n",
      "Epoch 371/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3120 - accuracy: 0.8724\n",
      "Epoch 372/1000\n",
      "250/250 [==============================] - 0s 961us/step - loss: 0.3120 - accuracy: 0.8715\n",
      "Epoch 373/1000\n",
      "250/250 [==============================] - 0s 951us/step - loss: 0.3114 - accuracy: 0.8717\n",
      "Epoch 374/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3114 - accuracy: 0.8700\n",
      "Epoch 375/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8712\n",
      "Epoch 376/1000\n",
      "250/250 [==============================] - 0s 959us/step - loss: 0.3121 - accuracy: 0.8710\n",
      "Epoch 377/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3114 - accuracy: 0.8725\n",
      "Epoch 378/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3118 - accuracy: 0.8712\n",
      "Epoch 379/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3124 - accuracy: 0.8727\n",
      "Epoch 380/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3123 - accuracy: 0.8715\n",
      "Epoch 381/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8720\n",
      "Epoch 382/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8701\n",
      "Epoch 383/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8730\n",
      "Epoch 384/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.8720\n",
      "Epoch 385/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8725\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8710\n",
      "Epoch 387/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.8730\n",
      "Epoch 388/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3111 - accuracy: 0.8737\n",
      "Epoch 389/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3108 - accuracy: 0.8711\n",
      "Epoch 390/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8721\n",
      "Epoch 391/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3110 - accuracy: 0.8724\n",
      "Epoch 392/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8725\n",
      "Epoch 393/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3113 - accuracy: 0.8721\n",
      "Epoch 394/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8717\n",
      "Epoch 395/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3112 - accuracy: 0.8726\n",
      "Epoch 396/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3113 - accuracy: 0.8727\n",
      "Epoch 397/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.8735\n",
      "Epoch 398/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.8724\n",
      "Epoch 399/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8731\n",
      "Epoch 400/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8712\n",
      "Epoch 401/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8727\n",
      "Epoch 402/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8723\n",
      "Epoch 403/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8716\n",
      "Epoch 404/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8733\n",
      "Epoch 405/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.8719\n",
      "Epoch 406/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.8737\n",
      "Epoch 407/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3119 - accuracy: 0.8721\n",
      "Epoch 408/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8754\n",
      "Epoch 409/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3099 - accuracy: 0.8727\n",
      "Epoch 410/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8715\n",
      "Epoch 411/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8719\n",
      "Epoch 412/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.8739\n",
      "Epoch 413/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8740\n",
      "Epoch 414/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8721\n",
      "Epoch 415/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8727\n",
      "Epoch 416/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.8740\n",
      "Epoch 417/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8740\n",
      "Epoch 418/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3113 - accuracy: 0.8726\n",
      "Epoch 419/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8745\n",
      "Epoch 420/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.8726\n",
      "Epoch 421/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8716\n",
      "Epoch 422/1000\n",
      "250/250 [==============================] - 0s 961us/step - loss: 0.3103 - accuracy: 0.8729\n",
      "Epoch 423/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3092 - accuracy: 0.8730\n",
      "Epoch 424/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3101 - accuracy: 0.8724\n",
      "Epoch 425/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3093 - accuracy: 0.8735\n",
      "Epoch 426/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8741\n",
      "Epoch 427/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3101 - accuracy: 0.8731\n",
      "Epoch 428/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3084 - accuracy: 0.8760\n",
      "Epoch 429/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3090 - accuracy: 0.8735\n",
      "Epoch 430/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3101 - accuracy: 0.8705\n",
      "Epoch 431/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3091 - accuracy: 0.8731\n",
      "Epoch 432/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3099 - accuracy: 0.8702\n",
      "Epoch 433/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3099 - accuracy: 0.8717\n",
      "Epoch 434/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3086 - accuracy: 0.8739\n",
      "Epoch 435/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8737\n",
      "Epoch 436/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3093 - accuracy: 0.8723\n",
      "Epoch 437/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3092 - accuracy: 0.8725\n",
      "Epoch 438/1000\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.3088 - accuracy: 0.8726\n",
      "Epoch 439/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3101 - accuracy: 0.8717\n",
      "Epoch 440/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3094 - accuracy: 0.8714\n",
      "Epoch 441/1000\n",
      "250/250 [==============================] - 0s 997us/step - loss: 0.3085 - accuracy: 0.8720\n",
      "Epoch 442/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3090 - accuracy: 0.8741\n",
      "Epoch 443/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3091 - accuracy: 0.8746\n",
      "Epoch 444/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3089 - accuracy: 0.8736\n",
      "Epoch 445/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3096 - accuracy: 0.8749\n",
      "Epoch 446/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8748\n",
      "Epoch 447/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3098 - accuracy: 0.8742\n",
      "Epoch 448/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3086 - accuracy: 0.8745\n",
      "Epoch 449/1000\n",
      "250/250 [==============================] - 0s 997us/step - loss: 0.3092 - accuracy: 0.8733\n",
      "Epoch 450/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3077 - accuracy: 0.8749\n",
      "Epoch 451/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3087 - accuracy: 0.8726\n",
      "Epoch 452/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3100 - accuracy: 0.8735\n",
      "Epoch 453/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3085 - accuracy: 0.8740\n",
      "Epoch 454/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3099 - accuracy: 0.8720\n",
      "Epoch 455/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3088 - accuracy: 0.8734\n",
      "Epoch 456/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3094 - accuracy: 0.8733\n",
      "Epoch 457/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3082 - accuracy: 0.8748\n",
      "Epoch 458/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3069 - accuracy: 0.8742\n",
      "Epoch 459/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3080 - accuracy: 0.8708\n",
      "Epoch 460/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3088 - accuracy: 0.8736\n",
      "Epoch 461/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3090 - accuracy: 0.8731\n",
      "Epoch 462/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3081 - accuracy: 0.8731\n",
      "Epoch 463/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3085 - accuracy: 0.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8724\n",
      "Epoch 465/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8721\n",
      "Epoch 466/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8740\n",
      "Epoch 467/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8721\n",
      "Epoch 468/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3083 - accuracy: 0.8717\n",
      "Epoch 469/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3088 - accuracy: 0.8723\n",
      "Epoch 470/1000\n",
      "250/250 [==============================] - 0s 981us/step - loss: 0.3077 - accuracy: 0.8758\n",
      "Epoch 471/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3075 - accuracy: 0.8736\n",
      "Epoch 472/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3078 - accuracy: 0.8739\n",
      "Epoch 473/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3071 - accuracy: 0.8740\n",
      "Epoch 474/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3091 - accuracy: 0.8737\n",
      "Epoch 475/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3076 - accuracy: 0.8759\n",
      "Epoch 476/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3076 - accuracy: 0.8745\n",
      "Epoch 477/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3080 - accuracy: 0.8752\n",
      "Epoch 478/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3074 - accuracy: 0.8750\n",
      "Epoch 479/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3076 - accuracy: 0.8740\n",
      "Epoch 480/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3088 - accuracy: 0.8740\n",
      "Epoch 481/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3081 - accuracy: 0.8737\n",
      "Epoch 482/1000\n",
      "250/250 [==============================] - 0s 990us/step - loss: 0.3081 - accuracy: 0.8735\n",
      "Epoch 483/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3080 - accuracy: 0.8744\n",
      "Epoch 484/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3073 - accuracy: 0.8720\n",
      "Epoch 485/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3070 - accuracy: 0.8749\n",
      "Epoch 486/1000\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.3076 - accuracy: 0.8750\n",
      "Epoch 487/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3093 - accuracy: 0.8737\n",
      "Epoch 488/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3073 - accuracy: 0.8751\n",
      "Epoch 489/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3077 - accuracy: 0.8725\n",
      "Epoch 490/1000\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.3081 - accuracy: 0.8739\n",
      "Epoch 491/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3075 - accuracy: 0.8746\n",
      "Epoch 492/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3081 - accuracy: 0.8737\n",
      "Epoch 493/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3088 - accuracy: 0.8719\n",
      "Epoch 494/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3064 - accuracy: 0.8770\n",
      "Epoch 495/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3081 - accuracy: 0.8729\n",
      "Epoch 496/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3071 - accuracy: 0.8745\n",
      "Epoch 497/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3077 - accuracy: 0.8745\n",
      "Epoch 498/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3071 - accuracy: 0.8742\n",
      "Epoch 499/1000\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.3070 - accuracy: 0.8745\n",
      "Epoch 500/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3085 - accuracy: 0.8744\n",
      "Epoch 501/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3073 - accuracy: 0.8723\n",
      "Epoch 502/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3080 - accuracy: 0.8745\n",
      "Epoch 503/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3073 - accuracy: 0.8740\n",
      "Epoch 504/1000\n",
      "250/250 [==============================] - 0s 948us/step - loss: 0.3073 - accuracy: 0.8744\n",
      "Epoch 505/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3070 - accuracy: 0.8733\n",
      "Epoch 506/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3076 - accuracy: 0.8758\n",
      "Epoch 507/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3071 - accuracy: 0.8741\n",
      "Epoch 508/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3065 - accuracy: 0.8755\n",
      "Epoch 509/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3064 - accuracy: 0.8745\n",
      "Epoch 510/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3071 - accuracy: 0.8750\n",
      "Epoch 511/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3077 - accuracy: 0.8750\n",
      "Epoch 512/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3071 - accuracy: 0.8729\n",
      "Epoch 513/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3070 - accuracy: 0.8726\n",
      "Epoch 514/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3080 - accuracy: 0.8723\n",
      "Epoch 515/1000\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.3069 - accuracy: 0.8760\n",
      "Epoch 516/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3068 - accuracy: 0.8730\n",
      "Epoch 517/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3066 - accuracy: 0.8731\n",
      "Epoch 518/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3074 - accuracy: 0.8745\n",
      "Epoch 519/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.8742\n",
      "Epoch 520/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3061 - accuracy: 0.8716\n",
      "Epoch 521/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3064 - accuracy: 0.8755\n",
      "Epoch 522/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3084 - accuracy: 0.8734\n",
      "Epoch 523/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3068 - accuracy: 0.8744\n",
      "Epoch 524/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3072 - accuracy: 0.8748\n",
      "Epoch 525/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3064 - accuracy: 0.8755\n",
      "Epoch 526/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3077 - accuracy: 0.8748\n",
      "Epoch 527/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8739\n",
      "Epoch 528/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3074 - accuracy: 0.8730\n",
      "Epoch 529/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8727\n",
      "Epoch 530/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.8724\n",
      "Epoch 531/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8749\n",
      "Epoch 532/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8751\n",
      "Epoch 533/1000\n",
      "250/250 [==============================] - 0s 998us/step - loss: 0.3066 - accuracy: 0.8739\n",
      "Epoch 534/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.8742\n",
      "Epoch 535/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.8731\n",
      "Epoch 536/1000\n",
      "250/250 [==============================] - 0s 967us/step - loss: 0.3068 - accuracy: 0.8735\n",
      "Epoch 537/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3059 - accuracy: 0.8758\n",
      "Epoch 538/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3063 - accuracy: 0.8744\n",
      "Epoch 539/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3055 - accuracy: 0.8758\n",
      "Epoch 540/1000\n",
      "250/250 [==============================] - 0s 966us/step - loss: 0.3065 - accuracy: 0.8721\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 974us/step - loss: 0.3063 - accuracy: 0.8748\n",
      "Epoch 542/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3055 - accuracy: 0.8735\n",
      "Epoch 543/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3065 - accuracy: 0.8746\n",
      "Epoch 544/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3071 - accuracy: 0.8735\n",
      "Epoch 545/1000\n",
      "250/250 [==============================] - 0s 982us/step - loss: 0.3061 - accuracy: 0.8756\n",
      "Epoch 546/1000\n",
      "250/250 [==============================] - 0s 949us/step - loss: 0.3057 - accuracy: 0.8740\n",
      "Epoch 547/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3070 - accuracy: 0.8744\n",
      "Epoch 548/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3061 - accuracy: 0.8744\n",
      "Epoch 549/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3064 - accuracy: 0.8737\n",
      "Epoch 550/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3065 - accuracy: 0.8734\n",
      "Epoch 551/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3066 - accuracy: 0.8737\n",
      "Epoch 552/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3061 - accuracy: 0.8740\n",
      "Epoch 553/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3066 - accuracy: 0.8724\n",
      "Epoch 554/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3063 - accuracy: 0.8754\n",
      "Epoch 555/1000\n",
      "250/250 [==============================] - 0s 944us/step - loss: 0.3059 - accuracy: 0.8755\n",
      "Epoch 556/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8750\n",
      "Epoch 557/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3059 - accuracy: 0.8742\n",
      "Epoch 558/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3068 - accuracy: 0.8744\n",
      "Epoch 559/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3054 - accuracy: 0.8750\n",
      "Epoch 560/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3062 - accuracy: 0.8744\n",
      "Epoch 561/1000\n",
      "250/250 [==============================] - 0s 970us/step - loss: 0.3071 - accuracy: 0.8755\n",
      "Epoch 562/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3077 - accuracy: 0.8746\n",
      "Epoch 563/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3065 - accuracy: 0.8740\n",
      "Epoch 564/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3063 - accuracy: 0.8724\n",
      "Epoch 565/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3057 - accuracy: 0.8756\n",
      "Epoch 566/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3062 - accuracy: 0.8741\n",
      "Epoch 567/1000\n",
      "250/250 [==============================] - 0s 961us/step - loss: 0.3054 - accuracy: 0.8734\n",
      "Epoch 568/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3057 - accuracy: 0.8763\n",
      "Epoch 569/1000\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.3061 - accuracy: 0.8749\n",
      "Epoch 570/1000\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.3053 - accuracy: 0.8751\n",
      "Epoch 571/1000\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.3052 - accuracy: 0.8764\n",
      "Epoch 572/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3064 - accuracy: 0.8746\n",
      "Epoch 573/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3058 - accuracy: 0.8761\n",
      "Epoch 574/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3065 - accuracy: 0.8731\n",
      "Epoch 575/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3053 - accuracy: 0.8752\n",
      "Epoch 576/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3060 - accuracy: 0.8751\n",
      "Epoch 577/1000\n",
      "250/250 [==============================] - 0s 948us/step - loss: 0.3070 - accuracy: 0.8742\n",
      "Epoch 578/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3052 - accuracy: 0.8756\n",
      "Epoch 579/1000\n",
      "250/250 [==============================] - 0s 948us/step - loss: 0.3055 - accuracy: 0.8756\n",
      "Epoch 580/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3052 - accuracy: 0.8766\n",
      "Epoch 581/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3061 - accuracy: 0.8745\n",
      "Epoch 582/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3056 - accuracy: 0.8746\n",
      "Epoch 583/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3052 - accuracy: 0.8767\n",
      "Epoch 584/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3055 - accuracy: 0.8748\n",
      "Epoch 585/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3053 - accuracy: 0.8764\n",
      "Epoch 586/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3055 - accuracy: 0.8749\n",
      "Epoch 587/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8755\n",
      "Epoch 588/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8755\n",
      "Epoch 589/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8755\n",
      "Epoch 590/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3056 - accuracy: 0.8739\n",
      "Epoch 591/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3055 - accuracy: 0.8748\n",
      "Epoch 592/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3050 - accuracy: 0.8755\n",
      "Epoch 593/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3053 - accuracy: 0.8759\n",
      "Epoch 594/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3053 - accuracy: 0.8746\n",
      "Epoch 595/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3055 - accuracy: 0.8736\n",
      "Epoch 596/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3045 - accuracy: 0.8752\n",
      "Epoch 597/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3055 - accuracy: 0.8751\n",
      "Epoch 598/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3060 - accuracy: 0.8758\n",
      "Epoch 599/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3060 - accuracy: 0.8739\n",
      "Epoch 600/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3049 - accuracy: 0.8739\n",
      "Epoch 601/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3048 - accuracy: 0.8756\n",
      "Epoch 602/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3047 - accuracy: 0.8749\n",
      "Epoch 603/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3057 - accuracy: 0.8744\n",
      "Epoch 604/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3050 - accuracy: 0.8744\n",
      "Epoch 605/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3044 - accuracy: 0.8766\n",
      "Epoch 606/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3056 - accuracy: 0.8760\n",
      "Epoch 607/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3054 - accuracy: 0.8760\n",
      "Epoch 608/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3040 - accuracy: 0.8729\n",
      "Epoch 609/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3050 - accuracy: 0.8766\n",
      "Epoch 610/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3046 - accuracy: 0.8752\n",
      "Epoch 611/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3046 - accuracy: 0.8756\n",
      "Epoch 612/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3064 - accuracy: 0.8749\n",
      "Epoch 613/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3044 - accuracy: 0.8756\n",
      "Epoch 614/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3042 - accuracy: 0.8767\n",
      "Epoch 615/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3039 - accuracy: 0.8764\n",
      "Epoch 616/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3041 - accuracy: 0.8751\n",
      "Epoch 617/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8761\n",
      "Epoch 618/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 957us/step - loss: 0.3046 - accuracy: 0.8754\n",
      "Epoch 619/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8745\n",
      "Epoch 620/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3056 - accuracy: 0.8755\n",
      "Epoch 621/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3053 - accuracy: 0.8755\n",
      "Epoch 622/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3049 - accuracy: 0.8735\n",
      "Epoch 623/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3053 - accuracy: 0.8761\n",
      "Epoch 624/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3044 - accuracy: 0.8749\n",
      "Epoch 625/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3043 - accuracy: 0.8748\n",
      "Epoch 626/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3041 - accuracy: 0.8741\n",
      "Epoch 627/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3038 - accuracy: 0.8754\n",
      "Epoch 628/1000\n",
      "250/250 [==============================] - 0s 948us/step - loss: 0.3047 - accuracy: 0.8746\n",
      "Epoch 629/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8773\n",
      "Epoch 630/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3038 - accuracy: 0.8748\n",
      "Epoch 631/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3042 - accuracy: 0.8766\n",
      "Epoch 632/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3056 - accuracy: 0.8754\n",
      "Epoch 633/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3046 - accuracy: 0.8750\n",
      "Epoch 634/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3044 - accuracy: 0.8748\n",
      "Epoch 635/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3038 - accuracy: 0.8777\n",
      "Epoch 636/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3035 - accuracy: 0.8749\n",
      "Epoch 637/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8751\n",
      "Epoch 638/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3045 - accuracy: 0.8739\n",
      "Epoch 639/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3040 - accuracy: 0.8726\n",
      "Epoch 640/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3048 - accuracy: 0.8748\n",
      "Epoch 641/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3046 - accuracy: 0.8744\n",
      "Epoch 642/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3046 - accuracy: 0.8763\n",
      "Epoch 643/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3047 - accuracy: 0.8763\n",
      "Epoch 644/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3033 - accuracy: 0.8759\n",
      "Epoch 645/1000\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.3053 - accuracy: 0.8748\n",
      "Epoch 646/1000\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.3053 - accuracy: 0.8754\n",
      "Epoch 647/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3033 - accuracy: 0.8775\n",
      "Epoch 648/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3045 - accuracy: 0.8761\n",
      "Epoch 649/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3039 - accuracy: 0.8755\n",
      "Epoch 650/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3041 - accuracy: 0.8771\n",
      "Epoch 651/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3043 - accuracy: 0.8769\n",
      "Epoch 652/1000\n",
      "250/250 [==============================] - 0s 961us/step - loss: 0.3037 - accuracy: 0.8749\n",
      "Epoch 653/1000\n",
      "250/250 [==============================] - 0s 944us/step - loss: 0.3041 - accuracy: 0.8740\n",
      "Epoch 654/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3032 - accuracy: 0.8763\n",
      "Epoch 655/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3041 - accuracy: 0.8765\n",
      "Epoch 656/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3043 - accuracy: 0.8769\n",
      "Epoch 657/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3032 - accuracy: 0.8744\n",
      "Epoch 658/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3036 - accuracy: 0.8759\n",
      "Epoch 659/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3040 - accuracy: 0.8754\n",
      "Epoch 660/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8749\n",
      "Epoch 661/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3033 - accuracy: 0.8754\n",
      "Epoch 662/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3040 - accuracy: 0.8773\n",
      "Epoch 663/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3030 - accuracy: 0.8766\n",
      "Epoch 664/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3058 - accuracy: 0.8739\n",
      "Epoch 665/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3040 - accuracy: 0.8764\n",
      "Epoch 666/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3034 - accuracy: 0.8760\n",
      "Epoch 667/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3045 - accuracy: 0.8748\n",
      "Epoch 668/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3035 - accuracy: 0.8731\n",
      "Epoch 669/1000\n",
      "250/250 [==============================] - 0s 948us/step - loss: 0.3037 - accuracy: 0.8756\n",
      "Epoch 670/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3036 - accuracy: 0.8750\n",
      "Epoch 671/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3031 - accuracy: 0.8756\n",
      "Epoch 672/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3035 - accuracy: 0.8756\n",
      "Epoch 673/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3026 - accuracy: 0.8765\n",
      "Epoch 674/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3049 - accuracy: 0.8750\n",
      "Epoch 675/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3046 - accuracy: 0.8750\n",
      "Epoch 676/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3033 - accuracy: 0.8740\n",
      "Epoch 677/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3048 - accuracy: 0.8765\n",
      "Epoch 678/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8744\n",
      "Epoch 679/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3034 - accuracy: 0.8745\n",
      "Epoch 680/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3055 - accuracy: 0.8742\n",
      "Epoch 681/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3042 - accuracy: 0.8766\n",
      "Epoch 682/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3027 - accuracy: 0.8755\n",
      "Epoch 683/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3034 - accuracy: 0.8749\n",
      "Epoch 684/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3048 - accuracy: 0.8742\n",
      "Epoch 685/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8761\n",
      "Epoch 686/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3038 - accuracy: 0.8746\n",
      "Epoch 687/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3027 - accuracy: 0.8748\n",
      "Epoch 688/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3043 - accuracy: 0.8763\n",
      "Epoch 689/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3037 - accuracy: 0.8751\n",
      "Epoch 690/1000\n",
      "250/250 [==============================] - 0s 965us/step - loss: 0.3029 - accuracy: 0.8752\n",
      "Epoch 691/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8761\n",
      "Epoch 692/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3031 - accuracy: 0.8775\n",
      "Epoch 693/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3038 - accuracy: 0.8752\n",
      "Epoch 694/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3048 - accuracy: 0.8746\n",
      "Epoch 695/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 968us/step - loss: 0.3039 - accuracy: 0.8752\n",
      "Epoch 696/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3038 - accuracy: 0.8764\n",
      "Epoch 697/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3038 - accuracy: 0.8748\n",
      "Epoch 698/1000\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.3024 - accuracy: 0.8740\n",
      "Epoch 699/1000\n",
      "250/250 [==============================] - 0s 957us/step - loss: 0.3042 - accuracy: 0.8758\n",
      "Epoch 700/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3035 - accuracy: 0.8739\n",
      "Epoch 701/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3038 - accuracy: 0.8744\n",
      "Epoch 702/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3033 - accuracy: 0.8765\n",
      "Epoch 703/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3022 - accuracy: 0.8760\n",
      "Epoch 704/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3019 - accuracy: 0.8777\n",
      "Epoch 705/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3035 - accuracy: 0.8744\n",
      "Epoch 706/1000\n",
      "250/250 [==============================] - 0s 971us/step - loss: 0.3028 - accuracy: 0.8760\n",
      "Epoch 707/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3026 - accuracy: 0.8760\n",
      "Epoch 708/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8750\n",
      "Epoch 709/1000\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8777\n",
      "Epoch 710/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8755\n",
      "Epoch 711/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3033 - accuracy: 0.8761\n",
      "Epoch 712/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3035 - accuracy: 0.8765\n",
      "Epoch 713/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3037 - accuracy: 0.8759\n",
      "Epoch 714/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3035 - accuracy: 0.8751\n",
      "Epoch 715/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3041 - accuracy: 0.8746\n",
      "Epoch 716/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3019 - accuracy: 0.8763\n",
      "Epoch 717/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3037 - accuracy: 0.8754\n",
      "Epoch 718/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3031 - accuracy: 0.8759\n",
      "Epoch 719/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3029 - accuracy: 0.8775\n",
      "Epoch 720/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3028 - accuracy: 0.8749\n",
      "Epoch 721/1000\n",
      "250/250 [==============================] - 0s 966us/step - loss: 0.3021 - accuracy: 0.8759\n",
      "Epoch 722/1000\n",
      "250/250 [==============================] - 0s 999us/step - loss: 0.3034 - accuracy: 0.8763\n",
      "Epoch 723/1000\n",
      "250/250 [==============================] - 0s 961us/step - loss: 0.3045 - accuracy: 0.8746\n",
      "Epoch 724/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3036 - accuracy: 0.8774\n",
      "Epoch 725/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3027 - accuracy: 0.8755\n",
      "Epoch 726/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3031 - accuracy: 0.8740\n",
      "Epoch 727/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3027 - accuracy: 0.8754\n",
      "Epoch 728/1000\n",
      "250/250 [==============================] - 0s 965us/step - loss: 0.3023 - accuracy: 0.8759\n",
      "Epoch 729/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3028 - accuracy: 0.8760\n",
      "Epoch 730/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3028 - accuracy: 0.8749\n",
      "Epoch 731/1000\n",
      "250/250 [==============================] - 0s 967us/step - loss: 0.3018 - accuracy: 0.8756\n",
      "Epoch 732/1000\n",
      "250/250 [==============================] - 0s 967us/step - loss: 0.3025 - accuracy: 0.8752\n",
      "Epoch 733/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3025 - accuracy: 0.8749\n",
      "Epoch 734/1000\n",
      "250/250 [==============================] - 0s 944us/step - loss: 0.3022 - accuracy: 0.8776\n",
      "Epoch 735/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3033 - accuracy: 0.8752\n",
      "Epoch 736/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3022 - accuracy: 0.8770\n",
      "Epoch 737/1000\n",
      "250/250 [==============================] - 0s 963us/step - loss: 0.3029 - accuracy: 0.8751\n",
      "Epoch 738/1000\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.3029 - accuracy: 0.8749\n",
      "Epoch 739/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3027 - accuracy: 0.8771\n",
      "Epoch 740/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3025 - accuracy: 0.8754\n",
      "Epoch 741/1000\n",
      "250/250 [==============================] - 0s 958us/step - loss: 0.3032 - accuracy: 0.8751\n",
      "Epoch 742/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3024 - accuracy: 0.8771\n",
      "Epoch 743/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3029 - accuracy: 0.8755\n",
      "Epoch 744/1000\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.3034 - accuracy: 0.8763\n",
      "Epoch 745/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3018 - accuracy: 0.8774\n",
      "Epoch 746/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3026 - accuracy: 0.8752\n",
      "Epoch 747/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3027 - accuracy: 0.8755\n",
      "Epoch 748/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3020 - accuracy: 0.8754\n",
      "Epoch 749/1000\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.3042 - accuracy: 0.8751\n",
      "Epoch 750/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3020 - accuracy: 0.8754\n",
      "Epoch 751/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8763\n",
      "Epoch 752/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8758\n",
      "Epoch 753/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3016 - accuracy: 0.8776\n",
      "Epoch 754/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3027 - accuracy: 0.8756\n",
      "Epoch 755/1000\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.3035 - accuracy: 0.8774\n",
      "Epoch 756/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3020 - accuracy: 0.8740\n",
      "Epoch 757/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3027 - accuracy: 0.8759\n",
      "Epoch 758/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3013 - accuracy: 0.8764\n",
      "Epoch 759/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8777\n",
      "Epoch 760/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3014 - accuracy: 0.8752\n",
      "Epoch 761/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3025 - accuracy: 0.8776\n",
      "Epoch 762/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3027 - accuracy: 0.8744\n",
      "Epoch 763/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3015 - accuracy: 0.8780\n",
      "Epoch 764/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3023 - accuracy: 0.8759\n",
      "Epoch 765/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3014 - accuracy: 0.8751\n",
      "Epoch 766/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3022 - accuracy: 0.8770\n",
      "Epoch 767/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3026 - accuracy: 0.8744\n",
      "Epoch 768/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8770\n",
      "Epoch 769/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8776\n",
      "Epoch 770/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3018 - accuracy: 0.8779\n",
      "Epoch 771/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3026 - accuracy: 0.8775\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 972us/step - loss: 0.3029 - accuracy: 0.8746\n",
      "Epoch 773/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3024 - accuracy: 0.8771\n",
      "Epoch 774/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3024 - accuracy: 0.8754\n",
      "Epoch 775/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3015 - accuracy: 0.8773\n",
      "Epoch 776/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3020 - accuracy: 0.8760\n",
      "Epoch 777/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3021 - accuracy: 0.8735\n",
      "Epoch 778/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3010 - accuracy: 0.8777\n",
      "Epoch 779/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3028 - accuracy: 0.8763\n",
      "Epoch 780/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3024 - accuracy: 0.8761\n",
      "Epoch 781/1000\n",
      "250/250 [==============================] - 0s 948us/step - loss: 0.3022 - accuracy: 0.8780\n",
      "Epoch 782/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3019 - accuracy: 0.8750\n",
      "Epoch 783/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3014 - accuracy: 0.8767\n",
      "Epoch 784/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3008 - accuracy: 0.8764\n",
      "Epoch 785/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3030 - accuracy: 0.8767\n",
      "Epoch 786/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3015 - accuracy: 0.8770\n",
      "Epoch 787/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3021 - accuracy: 0.8771\n",
      "Epoch 788/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3017 - accuracy: 0.8761\n",
      "Epoch 789/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3030 - accuracy: 0.8755\n",
      "Epoch 790/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3019 - accuracy: 0.8741\n",
      "Epoch 791/1000\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.3012 - accuracy: 0.8765\n",
      "Epoch 792/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3013 - accuracy: 0.8767\n",
      "Epoch 793/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3019 - accuracy: 0.8763\n",
      "Epoch 794/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3014 - accuracy: 0.8780\n",
      "Epoch 795/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3011 - accuracy: 0.8752\n",
      "Epoch 796/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3008 - accuracy: 0.8760\n",
      "Epoch 797/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3024 - accuracy: 0.8765\n",
      "Epoch 798/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3014 - accuracy: 0.8752\n",
      "Epoch 799/1000\n",
      "250/250 [==============================] - 0s 958us/step - loss: 0.3015 - accuracy: 0.8755\n",
      "Epoch 800/1000\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.3005 - accuracy: 0.8746\n",
      "Epoch 801/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3018 - accuracy: 0.8765\n",
      "Epoch 802/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3012 - accuracy: 0.8775\n",
      "Epoch 803/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3014 - accuracy: 0.8761\n",
      "Epoch 804/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3015 - accuracy: 0.8751\n",
      "Epoch 805/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3012 - accuracy: 0.8758\n",
      "Epoch 806/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3017 - accuracy: 0.8745\n",
      "Epoch 807/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3009 - accuracy: 0.8751\n",
      "Epoch 808/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.2999 - accuracy: 0.8770\n",
      "Epoch 809/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3008 - accuracy: 0.8798\n",
      "Epoch 810/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3014 - accuracy: 0.8786\n",
      "Epoch 811/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3022 - accuracy: 0.8771\n",
      "Epoch 812/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3007 - accuracy: 0.8756\n",
      "Epoch 813/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3018 - accuracy: 0.8763\n",
      "Epoch 814/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3022 - accuracy: 0.8773\n",
      "Epoch 815/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3007 - accuracy: 0.8766\n",
      "Epoch 816/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8766\n",
      "Epoch 817/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8767\n",
      "Epoch 818/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8749\n",
      "Epoch 819/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3021 - accuracy: 0.8749\n",
      "Epoch 820/1000\n",
      "250/250 [==============================] - 0s 981us/step - loss: 0.3009 - accuracy: 0.8750\n",
      "Epoch 821/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3014 - accuracy: 0.8770\n",
      "Epoch 822/1000\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.3005 - accuracy: 0.8761\n",
      "Epoch 823/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8769\n",
      "Epoch 824/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8770\n",
      "Epoch 825/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8752\n",
      "Epoch 826/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8775\n",
      "Epoch 827/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.8784\n",
      "Epoch 828/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8774\n",
      "Epoch 829/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.8758\n",
      "Epoch 830/1000\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8776\n",
      "Epoch 831/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8763\n",
      "Epoch 832/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8764\n",
      "Epoch 833/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3010 - accuracy: 0.8773\n",
      "Epoch 834/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3011 - accuracy: 0.8752\n",
      "Epoch 835/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3011 - accuracy: 0.8759\n",
      "Epoch 836/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8761\n",
      "Epoch 837/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.8784\n",
      "Epoch 838/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.8777\n",
      "Epoch 839/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3007 - accuracy: 0.8773\n",
      "Epoch 840/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3009 - accuracy: 0.8783\n",
      "Epoch 841/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3025 - accuracy: 0.8759\n",
      "Epoch 842/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3013 - accuracy: 0.8790\n",
      "Epoch 843/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3008 - accuracy: 0.8756\n",
      "Epoch 844/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3007 - accuracy: 0.8775\n",
      "Epoch 845/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3006 - accuracy: 0.8785\n",
      "Epoch 846/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3020 - accuracy: 0.8731\n",
      "Epoch 847/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3009 - accuracy: 0.8783\n",
      "Epoch 848/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3000 - accuracy: 0.8776\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 960us/step - loss: 0.3008 - accuracy: 0.8761\n",
      "Epoch 850/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3013 - accuracy: 0.8765\n",
      "Epoch 851/1000\n",
      "250/250 [==============================] - 0s 948us/step - loss: 0.3009 - accuracy: 0.8766\n",
      "Epoch 852/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3006 - accuracy: 0.8781\n",
      "Epoch 853/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3002 - accuracy: 0.8781\n",
      "Epoch 854/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3006 - accuracy: 0.8776\n",
      "Epoch 855/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3019 - accuracy: 0.8752\n",
      "Epoch 856/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3001 - accuracy: 0.8789\n",
      "Epoch 857/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3008 - accuracy: 0.8737\n",
      "Epoch 858/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8771\n",
      "Epoch 859/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8765\n",
      "Epoch 860/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3009 - accuracy: 0.8759\n",
      "Epoch 861/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3008 - accuracy: 0.8761\n",
      "Epoch 862/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3000 - accuracy: 0.8755\n",
      "Epoch 863/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3004 - accuracy: 0.8776\n",
      "Epoch 864/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3007 - accuracy: 0.8756\n",
      "Epoch 865/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3009 - accuracy: 0.8749\n",
      "Epoch 866/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3003 - accuracy: 0.8770\n",
      "Epoch 867/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3008 - accuracy: 0.8776\n",
      "Epoch 868/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.2997 - accuracy: 0.8773\n",
      "Epoch 869/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3008 - accuracy: 0.8754\n",
      "Epoch 870/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.3001 - accuracy: 0.8751\n",
      "Epoch 871/1000\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3004 - accuracy: 0.8763\n",
      "Epoch 872/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3011 - accuracy: 0.8765\n",
      "Epoch 873/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8774\n",
      "Epoch 874/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8769\n",
      "Epoch 875/1000\n",
      "250/250 [==============================] - 0s 940us/step - loss: 0.3002 - accuracy: 0.8788\n",
      "Epoch 876/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3015 - accuracy: 0.8771\n",
      "Epoch 877/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3020 - accuracy: 0.8770\n",
      "Epoch 878/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3008 - accuracy: 0.8767\n",
      "Epoch 879/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3002 - accuracy: 0.8770\n",
      "Epoch 880/1000\n",
      "250/250 [==============================] - 0s 965us/step - loss: 0.3004 - accuracy: 0.8783\n",
      "Epoch 881/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3001 - accuracy: 0.8766\n",
      "Epoch 882/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.3001 - accuracy: 0.8765\n",
      "Epoch 883/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.2998 - accuracy: 0.8783\n",
      "Epoch 884/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3001 - accuracy: 0.8774\n",
      "Epoch 885/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3000 - accuracy: 0.8781\n",
      "Epoch 886/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3012 - accuracy: 0.8771\n",
      "Epoch 887/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.2990 - accuracy: 0.8785\n",
      "Epoch 888/1000\n",
      "250/250 [==============================] - 0s 974us/step - loss: 0.2997 - accuracy: 0.8775\n",
      "Epoch 889/1000\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.2999 - accuracy: 0.8773\n",
      "Epoch 890/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3006 - accuracy: 0.8758\n",
      "Epoch 891/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.2997 - accuracy: 0.8773\n",
      "Epoch 892/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3011 - accuracy: 0.8780\n",
      "Epoch 893/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3006 - accuracy: 0.8776\n",
      "Epoch 894/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.3000 - accuracy: 0.8779\n",
      "Epoch 895/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8770\n",
      "Epoch 896/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3000 - accuracy: 0.8776\n",
      "Epoch 897/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.2998 - accuracy: 0.8789\n",
      "Epoch 898/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.2991 - accuracy: 0.8780\n",
      "Epoch 899/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.2998 - accuracy: 0.8791\n",
      "Epoch 900/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.2997 - accuracy: 0.8792\n",
      "Epoch 901/1000\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.2999 - accuracy: 0.8776\n",
      "Epoch 902/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3000 - accuracy: 0.8795\n",
      "Epoch 903/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3001 - accuracy: 0.8776\n",
      "Epoch 904/1000\n",
      "250/250 [==============================] - 0s 990us/step - loss: 0.3005 - accuracy: 0.8773\n",
      "Epoch 905/1000\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3008 - accuracy: 0.8769\n",
      "Epoch 906/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3009 - accuracy: 0.8771\n",
      "Epoch 907/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.2998 - accuracy: 0.8767\n",
      "Epoch 908/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.2992 - accuracy: 0.8780\n",
      "Epoch 909/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.2997 - accuracy: 0.8788\n",
      "Epoch 910/1000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3004 - accuracy: 0.8750\n",
      "Epoch 911/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.8764\n",
      "Epoch 912/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8765\n",
      "Epoch 913/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8799\n",
      "Epoch 914/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8771\n",
      "Epoch 915/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8789\n",
      "Epoch 916/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.2998 - accuracy: 0.8801\n",
      "Epoch 917/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.2992 - accuracy: 0.8785\n",
      "Epoch 918/1000\n",
      "250/250 [==============================] - 0s 981us/step - loss: 0.2988 - accuracy: 0.8801\n",
      "Epoch 919/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.2992 - accuracy: 0.8769\n",
      "Epoch 920/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.2990 - accuracy: 0.8789\n",
      "Epoch 921/1000\n",
      "250/250 [==============================] - 0s 994us/step - loss: 0.2996 - accuracy: 0.8777\n",
      "Epoch 922/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.2992 - accuracy: 0.8789\n",
      "Epoch 923/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8780\n",
      "Epoch 924/1000\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.2987 - accuracy: 0.8791\n",
      "Epoch 925/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.8770\n",
      "Epoch 926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1000us/step - loss: 0.2996 - accuracy: 0.8754\n",
      "Epoch 927/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8759\n",
      "Epoch 928/1000\n",
      "250/250 [==============================] - 0s 965us/step - loss: 0.2992 - accuracy: 0.8773\n",
      "Epoch 929/1000\n",
      "250/250 [==============================] - 0s 998us/step - loss: 0.2989 - accuracy: 0.8788\n",
      "Epoch 930/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8774\n",
      "Epoch 931/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.2997 - accuracy: 0.8776\n",
      "Epoch 932/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8791\n",
      "Epoch 933/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8790\n",
      "Epoch 934/1000\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.2997 - accuracy: 0.8763\n",
      "Epoch 935/1000\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.2997 - accuracy: 0.8795\n",
      "Epoch 936/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8763\n",
      "Epoch 937/1000\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.2999 - accuracy: 0.8760\n",
      "Epoch 938/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8774\n",
      "Epoch 939/1000\n",
      "250/250 [==============================] - 0s 986us/step - loss: 0.2995 - accuracy: 0.8798\n",
      "Epoch 940/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8789\n",
      "Epoch 941/1000\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.2988 - accuracy: 0.8784\n",
      "Epoch 942/1000\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.3003 - accuracy: 0.8774\n",
      "Epoch 943/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8770\n",
      "Epoch 944/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8791\n",
      "Epoch 945/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8779\n",
      "Epoch 946/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8770\n",
      "Epoch 947/1000\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.2993 - accuracy: 0.8790\n",
      "Epoch 948/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8783\n",
      "Epoch 949/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8781\n",
      "Epoch 950/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8798\n",
      "Epoch 951/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8784\n",
      "Epoch 952/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8784\n",
      "Epoch 953/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8794\n",
      "Epoch 954/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8781\n",
      "Epoch 955/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8784\n",
      "Epoch 956/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8766\n",
      "Epoch 957/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8796\n",
      "Epoch 958/1000\n",
      "250/250 [==============================] - 0s 986us/step - loss: 0.2988 - accuracy: 0.8784\n",
      "Epoch 959/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.2990 - accuracy: 0.8770\n",
      "Epoch 960/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8781\n",
      "Epoch 961/1000\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.3015 - accuracy: 0.8780\n",
      "Epoch 962/1000\n",
      "250/250 [==============================] - 0s 994us/step - loss: 0.2986 - accuracy: 0.8779\n",
      "Epoch 963/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8780\n",
      "Epoch 964/1000\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.3006 - accuracy: 0.8763\n",
      "Epoch 965/1000\n",
      "250/250 [==============================] - 0s 970us/step - loss: 0.2986 - accuracy: 0.8781\n",
      "Epoch 966/1000\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.2998 - accuracy: 0.8771\n",
      "Epoch 967/1000\n",
      "250/250 [==============================] - 0s 963us/step - loss: 0.2995 - accuracy: 0.8804\n",
      "Epoch 968/1000\n",
      "250/250 [==============================] - 0s 994us/step - loss: 0.2982 - accuracy: 0.8771\n",
      "Epoch 969/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.2996 - accuracy: 0.8773\n",
      "Epoch 970/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8799\n",
      "Epoch 971/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8785\n",
      "Epoch 972/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8777\n",
      "Epoch 973/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.8786\n",
      "Epoch 974/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8783\n",
      "Epoch 975/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8774\n",
      "Epoch 976/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8784\n",
      "Epoch 977/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8769\n",
      "Epoch 978/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8794\n",
      "Epoch 979/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8792\n",
      "Epoch 980/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.8773\n",
      "Epoch 981/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8766\n",
      "Epoch 982/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8771\n",
      "Epoch 983/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8789\n",
      "Epoch 984/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8761\n",
      "Epoch 985/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8775\n",
      "Epoch 986/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8781\n",
      "Epoch 987/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8776\n",
      "Epoch 988/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8780\n",
      "Epoch 989/1000\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.2992 - accuracy: 0.8770\n",
      "Epoch 990/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8790\n",
      "Epoch 991/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8788\n",
      "Epoch 992/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8777\n",
      "Epoch 993/1000\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.2988 - accuracy: 0.8779\n",
      "Epoch 994/1000\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.2985 - accuracy: 0.8774\n",
      "Epoch 995/1000\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.2988 - accuracy: 0.8795\n",
      "Epoch 996/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8791\n",
      "Epoch 997/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8767\n",
      "Epoch 998/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8795\n",
      "Epoch 999/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8790\n",
      "Epoch 1000/1000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6a4f8f310>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use a neural network to predict whether a customer will churn or not\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(15, input_shape=(None, 32, 15), activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b79efa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 774us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04266636],\n",
       "       [0.12028359],\n",
       "       [0.09449218],\n",
       "       [0.04952187],\n",
       "       [0.05991808],\n",
       "       [0.13988547],\n",
       "       [0.00951752],\n",
       "       [0.46041876],\n",
       "       [0.01550599],\n",
       "       [0.99512535]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is what the model predicts based off the test partition the percentage that the customer churns\n",
    "yprediction = model.predict(X_test)\n",
    "yprediction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "543f1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we make it so that if the value is more than 0.5 then it will give 1 or 0 which represents yes or no respectively\n",
    "yp=[]\n",
    "for i in yprediction:\n",
    "    if i > 0.5:\n",
    "        yp.append(1)\n",
    "    else:\n",
    "        yp.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11990e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "866f5407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5153    0\n",
       "4921    1\n",
       "7755    0\n",
       "5492    0\n",
       "2593    0\n",
       "1745    0\n",
       "7398    1\n",
       "8046    0\n",
       "3830    0\n",
       "4871    0\n",
       "2097    0\n",
       "4872    0\n",
       "5433    0\n",
       "8711    0\n",
       "1810    0\n",
       "1091    0\n",
       "7478    0\n",
       "6990    0\n",
       "2828    0\n",
       "2200    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "599f5500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here we plot a truth table to see how visualise the accuracy of the model\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=yp)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2d7272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      1595\n",
      "           1       0.64      0.49      0.55       405\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.76      0.71      0.73      2000\n",
      "weighted avg       0.83      0.84      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,yp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
